{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm8U2+l+h12aWOCOVc3pZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateusvillarroel/PythonXCohen/blob/main/Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IEbBUPGSQM5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80571bf6-d9dc-4fe7-aa7f-6f64b94e3e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: webvtt-py in /usr/local/lib/python3.12/dist-packages (0.5.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# import modules and libraries\n",
        "!pip install webvtt-py\n",
        "import webvtt\n",
        "import re\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vtt = webvtt.read('/content/drive/MyDrive/Colab Notebooks/PythonXCohen/MasterPython_CodeAndData/textSearchReplace/captions_text.vtt')\n",
        "vtt = str(vtt)\n",
        "print(vtt)"
      ],
      "metadata": {
        "id": "45SmLWQ0xF_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r\"\\d{2}:\\d{2}:\\d{2}\\.\\d{3}\"\n",
        "vtt_timestamps = re.sub(pattern, '', vtt)\n",
        "print(vtt_timestamps)"
      ],
      "metadata": {
        "id": "124ydpWmDbVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern_4_letter_words = r\"\\b([A-Za-z])[A-Za-z]{3}\\b\"\n",
        "vtt_bad_word_free = re.sub(pattern_4_letter_words, r\"\\1***\", vtt_timestamps)\n",
        "print(vtt_bad_word_free)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6paaT_mgjAvl",
        "outputId": "e7767b25-14de-4123-b3c4-4b0bbfd48af5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  I'm now going to g*** you two m*** example problems of computing.\n",
            "  eigendecomposition of matrices by h***.\n",
            "  Obviously t*** is on the computer but I encourage you to do these problems by h*** and t***'re not d***\n",
            "  in Matlab.\n",
            "  So I guess t***'s w*** it means by h***.\n",
            "  So let's get started.\n",
            "  H*** is a two by two matrix and you should pause the video go through f*** the eigenvalues and the eigenvectors\n",
            "  of t*** matrix so the way we start is by shifting the matrix by Lambda so subtracting lambda f*** the\n",
            "  diagonal elements setting the determinant equal to z*** and t*** proceeding to compute the determinant\n",
            "  which is a*** called the characteristic equation of t*** matrix.\n",
            "  So t*** works out to be three minus lambda times six minus lambda minus f*** equals z*** and t*** expanding\n",
            "  these two terms multiplying out these two terms and t*** collecting the l*** terms gives us lambda squared\n",
            "  minus n*** lambda p*** fourteen equals z*** and t*** t*** expression h*** can be factored i*** lambda\n",
            "  minus seven and Lambda minus two and now it's pretty e*** to see t*** the two lambdas t*** w*** solve\n",
            "  t*** equation t*** solve t*** equation.\n",
            "  In other words the two eigenvalues of t*** matrix are p*** 7 and p*** two.\n",
            "  So t*** was s*** one we found the eigenvalues of t*** matrix and now we go through for e*** of these\n",
            "  eigenvalues shift the matrix by t*** amount by t*** value and t*** figure out w*** is a vector in the\n",
            "  shifted matrices n*** space.\n",
            "  OK so let's start w*** 2.\n",
            "  So t*** gives us the matrix 1 1 4 4.\n",
            "  And now we w*** to f*** the missing vector h*** and you've probably guessed it already it is 1 minus\n",
            "  1.\n",
            "  And of course you k*** t*** a*** acceptable would be minus 1 1 or minus quadrillion p*** quadrillion.\n",
            "  T*** vector simply identifies a subspace for the n*** space of t*** shifted matrix in any vector t***'s\n",
            "  in t*** n*** space is perfectly f*** as an eigenvector.\n",
            "  Now t*** s*** the b*** choice for an eigenvector would be a vector t*** has a n*** of 1 a magnitude\n",
            "  of 1.\n",
            "  And the second b*** choice would be integer values t*** are e*** to interpret and compact to write l***\n",
            "  t***.\n",
            "  All right.\n",
            "  So t*** was for two.\n",
            "  Now we go to the second eigenvalues which was seven and t*** gives us t*** matrix minus 4 1 and 4 minus\n",
            "  1.\n",
            "  And h*** a vector t*** could w*** as an eigenvector as a basis for the n*** space of t*** shifted matrix\n",
            "  is the numbers 1 4.\n",
            "  So h*** is the big picture overview we h*** t*** matrix and h*** you see the eigenvalue and its corresponding\n",
            "  eigenvector and the other eigenvalue and the other corresponding eigenvector.\n",
            "  Now y*** results w*** be correct.\n",
            "  If you h*** the correct pairing of eigenvalue and any multiple any scaled version of t*** vector; it\n",
            "  doesn't matter if you c*** t*** lambda one and t*** V one t***'s f*** because there's no intrinsic ordering.\n",
            "  W*** matters is t*** you h*** the pairing correct.\n",
            "  All right.\n",
            "  So t*** was the two by two c***.\n",
            "  Now let's go for a three by three c***.\n",
            "  T*** one is a little bit m*** challenging and I h*** to admit.\n",
            "  So I first c*** up w*** these numbers and t*** I started computing the eigendecomposition.\n",
            "  Now I h*** to admit t*** I got stuck on one of the eigenvectors.\n",
            "  I couldn't quite figure it out on my own.\n",
            "  So I u*** Matlab to compute t***\n",
            "  eigenvector.\n",
            "  So w*** I encourage you to do is f*** all three eigenvalues by h*** and I think it w*** be pretty obvious\n",
            "  w*** you start working through it which is the difficult eigenvalue.\n",
            "  So t*** w*** you should do by h*** is f*** two of the eigenvectors t*** you can get basically j*** by\n",
            "  k*** of eyeballing and making s*** educated guesses.\n",
            "  And t*** the third eigenvector you can use a computer to solve or you can j*** w*** and watch me c***\n",
            "  up w*** a solution.\n",
            "  All right.\n",
            "  So again we start by shifting t*** matrix by minus lambda setting the determinant equal to z*** and\n",
            "  t*** proceeding to compute the determinant of t*** equation and altogether t*** gives us the characteristic\n",
            "  equation of t*** matrix.\n",
            "  Now t*** is a little bit longer.\n",
            "  It's a little bit trickier the arithmetic g*** a little bit hairy in particular you end up w*** t***\n",
            "  minus lambda cubed t*** as w*** as a couple of multiple terms w*** Lambda and Lambda squared.\n",
            "  Now o*** you collect all of these l*** terms you'll end up w*** an expression t*** looks l*** t***.\n",
            "  So it should be minus lambda cubed p*** 10 times lambda squared p*** eleven lambda equals z*** Now something\n",
            "  interesting has happened h*** all of these terms h*** a lambda attached to t*** which means t*** we\n",
            "  can t*** a lambda out of e*** of these terms and rewrite t*** expression as minus lambda times.\n",
            "  All of t*** stuff and immediately t*** tells us t*** lambda equals z*** is a solution.\n",
            "  So w*** you set t*** lambda to be z*** it doesn't actually matter w***'s inside t*** parenthetical statement\n",
            "  t***'s immediately going to set to m*** t*** equation t***.\n",
            "  T*** means t*** one of the eigenvalues of t*** matrix is z*** and I'm going to h*** an entire video\n",
            "  j*** about t*** phenomenon a little bit later in t*** section.\n",
            "  But essentially w*** an eigenvector is an eigenvalue is z***.\n",
            "  It means t*** the matrix is singular and t*** you can actually see by looking at t*** matrix and you\n",
            "  see t*** column 1 p*** column 2 equals column 3 so whenever you h*** a singular matrix at least one\n",
            "  eigenvalues value is going to be equal to z***.\n",
            "  And in f*** the number of eigenvalues t*** are equal to z*** tells you about the r*** of t*** matrix.\n",
            "  M*** on t*** in the later video.\n",
            "  Now o*** you've gotten to t*** s*** you can further factor t*** equation and you end up w*** the result\n",
            "  t*** lambda equals z*** lambda equals minus 1 and Lambda equals eleven.\n",
            "  So you can probably guess t*** t*** is going to be the tricky I can value to compute the corresponding\n",
            "  I can vector of and t*** is the one t*** I got a little bit stuck w***.\n",
            "  And so I u*** Matlab as a crutch.\n",
            "  I cheated a little bit.\n",
            "  OK so but let's go through all of these.\n",
            "  So we start w*** z*** and now t*** is k*** of a funny thing because we are shifting the matrix by z***\n",
            "  which actually means we're not changing the matrix at all.\n",
            "  And t*** means t*** t*** matrix A already has a non-trivial n*** space e*** without doing any shifting.\n",
            "  So t*** problem actually boils d*** to finding a vector in the n*** space or a basis for the n*** space.\n",
            "  E*** without doing any shifting so based on w*** I j*** t*** you about how do I set up t*** matrix t***\n",
            "  column one p*** column two equals column three a basis for the n*** space is 1 one minus 1.\n",
            "  So you can try for e*** of these r*** the first column p*** the second column minus the third column\n",
            "  equals z*** all right.\n",
            "  So now let's m*** on.\n",
            "  So now we shift t*** matrix by eleven and t*** is basically where I got stuck and switch to matlab.\n",
            "  So it turns out t*** eigenvector is nineteen forty one and thirty six.\n",
            "  So if you figured out t*** I can vector on y*** own without using a computer t*** g*** for you you are\n",
            "  a better or at least m*** patient mathematician t*** I am.\n",
            "  And t*** we get to the third eigenvalue which was minus one.\n",
            "  So now t*** becomes p*** one.\n",
            "  And h*** is t*** shifted matrix and t*** one you should be a*** to solve on y*** own.\n",
            "  In f*** it's e*** easier t*** it looks.\n",
            "  And if you n*** a h*** before I s*** the answer t*** the h*** is j*** consider t*** t*** third column\n",
            "  is actually pretty useless if you get rid of t*** third column it becomes really e*** to f*** the \n",
            "  eigenvector in t*** shifted matrices n*** space.\n",
            "  So in f*** it's one minus one and t*** z*** you j*** set the third element to be z***.\n",
            "  So t*** leads us to the big picture overview of the eigendecomposition of t*** three by three singular\n",
            "  matrix r*** 2 matrix we h*** eigenvalues 0 minus 11 and minus 1.\n",
            "  And these are the corresponding eigenvectors.\n",
            "  And notice I've written t*** as row vectors and t*** transpose.\n",
            "  So these are still column vectors we generally always think about eigenvectors as column vectors and\n",
            "  you w*** learn m*** about why t*** is the c*** in the video on diagonalization, which is coming up s***.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern_excessive_spaces = r\"\\s{2,}\"\n",
        "vtt_beautiful = re.sub(pattern_excessive_spaces, ' ', vtt_bad_word_free)\n",
        "print(vtt_beautiful[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRUTaLcLmgq_",
        "outputId": "e48fb97f-61b6-43a6-ce7b-9acd2ad378cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm now going to g*** you two m*** example problems of computing. eigendecomposition of matrices by h***. Obviously t*** is on the computer but I encourage you to do these problems by h*** and t***'re not d*** in Matlab. So I guess t***'s w*** it means by h***. So let's get started. H*** is a two by two matrix and you should pause the video go through f*** the eigenvalues and the eigenvectors of t*** matrix so the way we start is by shifting the matrix by Lambda so subtracting lambda f*** the diagonal elements setting the determinant equal to z*** and t*** proceeding to compute the determinant which is a*** called the characteristic equation of t*** matrix. So t*** works out to be three minus lambda times six minus lambda minus f*** equals z*** and t*** expanding these two terms multiplying out these two terms and t*** collecting the l*** terms gives us lambda squared minus n*** lambda p*** fourteen equals z*** and t*** t*** expression h*** can be factored i*** lambda minus seven and Lambda minus two and now it's pretty e*** to see t*** the two lambdas t*** w*** solve t*** equation t*** solve t*** equation. In other words the two eigenvalues of t*** matrix are p*** 7 and p*** two. So t*** was s*** one we found the eigenvalues of t*** matrix and now we go through for e*** of these eigenvalues shift the matrix by t*** amount by t*** value and t*** figure out w*** is a vector in the shifted matrices n*** space. OK so let's start w*** 2. So t*** gives us the matrix 1 1 4 4. And now we w*** to f*** the missing vector h*** and you've probably guessed it already it is 1 minus 1. And of course you k*** t*** a*** acceptable would be minus 1 1 or minus quadrillion p*** quadrillion. T*** vector simply identifies a subspace for the n*** space of t*** shifted matrix in any vector t***'s in t*** n*** space is perfectly f*** as an eigenvector. Now t*** s*** the b*** choice for an eigenvector would be a vector t*** has a n*** of 1 a magnitude of 1. And the second b*** choice would be integer values t*** are e*** to interpret and compact to write l*** t***. All right. So t*** was for two. Now we go to the second eigenvalues which was seven and t*** gives us t*** matrix minus 4 1 and 4 minus 1. And h*** a vector t*** could w*** as an eigenvector as a basis for the n*** space of t*** shifted matrix is the numbers 1 4. So h*** is the big picture overview we h*** t*** matrix and h*** you see the eigenvalue and its corresponding eigenvector and the other eigenvalue and the other corresponding eigenvector. Now y*** results w*** be correct. If you h*** the correct pairing of eigenvalue and any multiple any scaled version of t*** vector; it doesn't matter if you c*** t*** lambda one and t*** V one t***'s f*** because there's no intrinsic ordering. W*** matters is t*** you h*** the pairing correct. All right. So t*** was the two by two c***. Now let's go for a three by three c***. T*** one is a little bit m*** challenging and I h*** to admit. So I first c*** up w*** these numbers and t*** I started computing the eigendecomposition. Now I h*** to admit t*** I got stuck on one of the eigenvectors. I couldn't quite figure it out on my own. So I u*** Matlab to compute t*** eigenvector. So w*** I encourage you to do is f*** all three eigenvalues by h*** and I think it w*** be pretty obvious w*** you start working through it which is the difficult eigenvalue. So t*** w*** you should do by h*** is f*** two of the eigenvectors t*** you can get basically j*** by k*** of eyeballing and making s*** educated guesses. And t*** the third eigenvector you can use a computer to solve or you can j*** w*** and watch me c*** up w*** a solution. All right. So again we start by shifting t*** matrix by minus lambda setting the determinant equal to z*** and t*** proceeding to compute the determinant of t*** equation and altogether t*** gives us the characteristic equation of t*** matrix. Now t*** is a little bit longer. It's a little bit trickier the arithmetic g*** a little bit hairy in particular you end up w*** t*** minus lambda cubed t*** as w*** as a couple of multiple terms w*** Lambda and Lambda squared. Now o*** you collect all of these l*** terms you'll end up w*** an expression t*** looks l*** t***. So it should be minus lambda cubed p*** 10 times lambda squared p*** eleven lambda equals z*** Now something interesting has happened h*** all of these terms h*** a lambda attached to t*** which means t*** we can t*** a lambda out of e*** of these terms and rewrite t*** expression as minus lambda times. All of t*** stuff and immediately t*** tells us t*** lambda equals z*** is a solution. So w*** you set t*** lambda to be z*** it doesn't actually matter w***'s inside t*** parenthetical statement t***'s immediately going to set to m*** t*** equation t***. T*** means t*** one of the eigenvalues of t*** matrix is z*** and I'm going to h*** an entire video j*** about t*** phenomenon a little bit later in t*** section. But essentially w*** an eigenvector is an eigenvalue is z***. It means t*** the matrix is singular and t*** you can actually see by looking at t*** matrix and you see t*** column 1 p*** column 2 equals column 3 so whenever you h*** a singular matrix at least one eigenvalues value is going to be equal to z***. And in f*** the number of eigenvalues t*** are equal to z*** tells you about the r*** of t*** matrix. M*** on t*** in the later video. Now o*** you've gotten to t*** s*** you can further factor t*** equation and you end up w*** the result t*** lambda equals z*** lambda equals minus 1 and Lambda equals eleven. So you can probably guess t*** t*** is going to be the tricky I can value to compute the corresponding I can vector of and t*** is the one t*** I got a little bit stuck w***. And so I u*** Matlab as a crutch. I cheated a little bit. OK so but let's go through all of these. So we start w*** z*** and now t*** is k*** of a funny thing because we are shifting the matrix by z*** which actually means we're not changing the matrix at all. And t*** means t*** t*** matrix A already has a non-trivial n*** space e*** without doing any shifting. So t*** problem actually boils d*** to finding a vector in the n*** space or a basis for the n*** space. E*** without doing any shifting so based on w*** I j*** t*** you about how do I set up t*** matrix t*** column one p*** column two equals column three a basis for the n*** space is 1 one minus 1. So you can try for e*** of these r*** the first column p*** the second column minus the third column equals z*** all right. So now let's m*** on. So now we shift t*** matrix by eleven and t*** is basically where I got stuck and switch to matlab. So it turns out t*** eigenvector is nineteen forty one and thirty six. So if you figured out t*** I can vector on y*** own without using a computer t*** g*** for you you are a better or at least m*** patient mathematician t*** I am. And t*** we get to the third eigenvalue which was minus one. So now t*** becomes p*** one. And h*** is t*** shifted matrix and t*** one you should be a*** to solve on y*** own. In f*** it's e*** easier t*** it looks. And if you n*** a h*** before I s*** the answer t*** the h*** is j*** consider t*** t*** third column is actually pretty useless if you get rid of t*** third column it becomes really e*** to f*** the eigenvector in t*** shifted matrices n*** space. So in f*** it's one minus one and t*** z*** you j*** set the third element to be z***. So t*** leads us to the big picture overview of the eigendecomposition of t*** three by three singular matrix r*** 2 matrix we h*** eigenvalues 0 minus 11 and minus 1. And these are the corresponding eigenvectors. And notice I've written t*** as row vectors and t*** transpose. So these are still column vectors we generally always think about eigenvectors as column vectors and you w*** learn m*** about why t*** is the c*** in the video on diagonalization, which is coming up s***.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('final_subtitle.txt', 'w') as f:\n",
        "  f.write(vtt_beautiful)\n",
        "\n",
        "  files.download('final_subtitle.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6o5ZZ88esMUL",
        "outputId": "f8f3c261-b729-4553-b40a-6ae8455c0f23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_54958e17-b830-4a5d-b3ee-76c1afdf5a02\", \"final_subtitle.txt\", 0)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
